---
title: "Precise temporal localisation of M/EEG effects with Bayesian generalised additive multilevel models"
shorttitle: "Bayesian modelling of M/EEG data"
author:
  - name: Ladislas Nalborczyk
    corresponding: true
    orcid: 0000-0002-7419-9855
    email: ladislas.nalborczyk@cnrs.fr
    url: https://lnalborczyk.github.io
    affiliations:
      - id: id1
        name: "Aix Marseille Univ, CNRS, LPL"
        address: "5 avenue Pasteur"
        city: "13100 Aix-en-Provence"
        country: France
  - name: Paul Bürkner
    orcid: 0000-0001-5765-8995
    url: https://paulbuerkner.com
    affiliations:
      - name: "TU Dortmund University, Department of Statistics"
author-note:
  disclosures:
    conflict-of-interest: "The authors have no conflicts of interest to disclose."
    # financial-support: "This study was supported by Grant [Grant Number] from [Funding Source]."
abstract: "Time-resolved electrophysiological measurements such as those offered by magneto- or electro-encephalography (M/EEG) provide a unique window onto neural activity underlying cognitive processes. Typically, researchers are interested in testing whether and when such measures differ across conditions and/or groups. The conventional approach consists in conducting mass-univariate statistics through time followed by some form of multiplicity correction (e.g., FDR, FWER) or cluster-based inference. However, these cluster-based methods have an important downside: they shift the focus of inference from the timepoint to the cluster level, thus preventing any conclusion to be made about the onset or offset of effects (e.g., differences across conditions or groups). Here, we introduce a *model-based* approch for analysing M/EEG timeseries such as ERPs or timecourses of decoding performance and their differences across conditions or groups. This approach relies on Bayesian generalised additive multilevel models, which output the posterior probabilility of the effect being above 0 (or above chance) at every timestep, while naturally taking into account the temporal dependencies and between-subject variability present in such data. Using both simulation and actual EEG data, we show that the proposed approach largely outperforms conventional methods in determining both the onset and offset of M/EEG effects (e.g., ERPs difference, decoding performance), producting more precise and more reliable estimates. We provide an R package implementing the approach and illustrate how to integrate it into M/EEG statistical pipelines in MNE-Python."
keywords: [EEG, MEG, generalised additive models, mixed-effects models, multilevel models, Bayesian statistics, brms]
floatsintext: true
numbered-lines: true
bibliography:
  - meeg_modelling.bib
  - grateful-refs.bib
suppress-title-page: false
link-citations: true
# see https://www.overleaf.com/learn/latex/Font_typefaces
# and systemfonts::system_fonts()
# pdf-engine: xelatex
# monofont: Roboto
mainfont: CMU Serif
fontsize: 10pt
draftfirst: false
draftall: false
a4paper: true
donotrepeattitle: true
lang: en
toc: true
language:
  citation-last-author-separator: "&"
  email: "email"
  title-block-author-note: "Author note"
  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; https://credit.niso.org/) as follows:"
format:
  # apaquarto-html: default
  apaquarto-pdf:
    latex-engine: xelatex
    documentmode: doc # man, jou, doc, stu
    keep-tex: true
    include-in-header:
      - text: |
          \usepackage{mathtools}
---

```{r setup, include = FALSE}
# loading packages
library(changepoint)
library(tidyverse)
library(tidybayes)
library(patchwork)
library(MetBrewer)
library(grateful)
library(ggrepel)
library(scales)
library(pakret)
library(scico)
library(knitr)
library(brms)

# setting knitr options
knitr::opts_chunk$set(
    cache = TRUE,
    eval = TRUE,
    echo = TRUE,
    warning = FALSE,
    message = FALSE,
    fig.align = "center",
    out.width = "100%",
    fig.asp = 0.75,
    fig.pos = "!htb",
    dev = "cairo_pdf"
    )

# setting a default ggplot2 theme
theme_set(theme_light(base_size = 10, base_family = "Open Sans") )

# template for citing R packages
# pkrt_set(pkg = "the `R` package `:pkg` [:ref]")
pkrt_set(pkg = "the `R` package `:pkg` v :ver [:ref]")
```

# Introduction

Here are some useful references to be discussed [@combrisson_exceeding_2015; @ehinger_unfold_2019; @hayasaka_validating_2003; @luck_how_2017; @pedersen_hierarchical_2019; @frossard2021; @frossard2022; @gramfort2013; @maris2007; @pernet2015]... See also @maris2011 and @rosenblatt2018 (history of cluster-based approaches)... Clusters failures [@eklund2016]...

## Previous work

Recent example of GLM for EEG [@wüllhorst2025; @fischer2013]... See also [@rousselet2008; @hauk2006]... Example of two-stage regression analysis [i.e., individual-level then group-level, @dunagan2024]...

From @dimigen2021: Recently, spline regression has been applied to ERPs [e.g., @hendrix2017; @kryuchkova2012]... GAMMs for EEG data [@abugaber2023; @meulman2015]...

Disentangling overlapping processes [@skukies_brain_2024; @skukies_modelling_2021]... Weighting single trials [@pernet2022]... The LIMO toolbox [@pernet2011]...

Using Bayes factors for decoding performance [@teichmann2022]...

## Bayesian regression modelling

Short intro/recap about Bayesian (linear and generalised) regression models...

## Generalised additive models

See for instance these tutorials [@sóskuthy2017; @winter2016] or application to phonetic data [@wieling2018] or this introduction [@baayen2020] or these reference books [@hastie2017; @wood2017]... application to pupillometry [@vanrij2019]... GAMLSS for neuroimaging data [@dinga2021]...

In generalised additive models (GAMs), the functional relationship between predictors and response variable is decomposed into a sum of low-dimensional non-parametric functions. A typical GAM has the following form:

$$
\begin{aligned} 
y_{i} &\sim \mathrm{EF}\left(\mu_{i}, \phi\right)\\
g\left(\mu_i\right) &=  \underbrace{A_{i} + \mathbf{X}_{i} \gamma}_{\text{parametric part}} + \underbrace{\sum_{j=1}^{J} f_{j}\left(x_{ij}\right)}_{\text{non-parametric part}}
\end{aligned}
$$

where $y_{i} \sim \mathrm{EF}\left(\mu_{i}, \phi\right)$ denotes that the observations $y_{i}$ are distributed as some member of the exponential family of distributions (e.g., Gaussian, Gamma, Beta, Poisson) with mean $\mu_{i}$ and scale parameter $\phi$; $g(\cdot)$ is the link function, $A$ is an offset, $\mathbf{X}_{i}$ is the $i$th row of a parametric model matrix, $\gamma$ is a vector of parameters for the parametric terms, $f_{j}$ is a smooth function of covariate $x_{j}$. The smooth functions $f_{j}$ are represented in the model via penalised splines basis expansions of the covariates, that are a weighted sum of basis functions:

$$
f_{j}\left(x_{i j}\right) = \sum_{k=1}^K \beta_{jk} b_{jk}\left(x_{ij}\right)
$$

where $\beta_{jk}$ is the weight (coefficient) associated with the $k$th basis function $b_{jk}()$ evaluated at the covariate value $x_{ij}$ for the $j$th smooth function $f_{j}$. Splines coefficients are penalised (usually through the squared of the smooth functions' second derivative) in a way that can be interpreted as a prior on the "wiggliness" of the function...

## Bayesian generalised additive multilevel models

Now describe the Bayesian GAMM... Proper inclusion of varying/random effects in the model specification protects against overly wiggly curves [@baayen2020]...

```{=html}
<!--

## Gaussian process regression

A Gaussian process (GP) is a stochastic process that defines the distribution over a collection of random variables indexed by a continuous variable, that is $\{f(t): t \in \mathcal{T}\}$ for some index set $\mathcal{T}$ [@riutort-mayol_practical_2023; @rasmussen2005]. Whereas Bayesian linear regression outputs a distribution over the parameters of some predefind parametric model, the GP approach, in contrast, is a non-parametric approach, in that it finds a distribution over the possible functions that are consistent with the observed data. However, note that nonparametric does not mean there aren't parameters, it means that there are infinitely many parameters.

From [brms documentation](https://www.rdocumentation.org/packages/brms/versions/2.22.0/topics/gp): A GP is a stochastic process, which describes the relation between one or more predictors $x=\left(x_{1}, \ldots, x_{d}\right)$ and a response $f(x)$, where $d$ is the number of predictors. A GP is the generalization of the multivariate normal distribution to an infinite number of dimensions. Thus, it can be interpreted as a prior over functions. The values of $f()$ at any finite set of locations are jointly multivariate normal, with a covariance matrix defined by the covariance kernel $k_p\left(x_i, x_j\right)$, where $p$ is the vector of parameters of the GP:

$$
\left(f\left(x_{1}\right), \ldots f\left(x_{n}\right) \sim \operatorname{MVN}\left(0, \left(k_p\left(x_{i}, x_{j}\right)\right)_{i, j=1}^{n}\right)\right.
$$

The smoothness and general behaviour of the function $f$ depends only on the choice of covariance kernel, which ensures that values that are close together in the input space will be mapped to similar output values...

From this perspective, $f$ is a realisation of an infinite dimensional normal distribution:

$$
f \sim \mathrm{Normal}(0, C(\lambda))
$$

where $C$ is a covariance kernel with hyperparameters $\lambda$ that defines the covariance between two function values $f\left(t_1\right)$ and $f\left(t_2\right)$ for two time points $t_1$ and $t_2$ [@rasmussen2005]. Similar to the different choices of the basis function for splines, different choices of the covariance kernel lead to different GPs. In this article, we consider the squared-exponential (a.k.a. radial basis function) kernel, which computes the squared distance between points and converts it into a measure of similarity. It is defined as:

$$
C(\lambda) := C\left(t_1, t_2, \sigma, \gamma\right) := \sigma^2 \exp \left(-\frac{||t_1-t_2||^{2}}{2 \gamma^2}\right)
$$

with hyperparameters $\lambda = (\sigma, \gamma)$, expressing the overall scale of GP and the length-scale, respectively [@rasmussen2005]. The advantages of this kernel are that it is computationally efficient and (infinitely) smooth making it a reasonable choice for the purposes of the present article. Here again, $\lambda$ hyperparameters are estimated from the data, along with all other model parameters.

Taken from <https://michael-franke.github.io/Bayesian-Regression/practice-sheets/10c-Gaussian-processes.html>: For a given vector $\mathbf{x}$, we can use the kernel to construct finite multi-variate normal distribution associated with it like so:

$$
\mathbf{x} \mapsto_{G P} \operatorname{MVNormal}(m(\mathbf{x}), k(\mathbf{x}, \mathbf{x}))
$$

where $m$ is a function that specifies the mean for the distribution associated with $\mathbf{x}$. This mapping is essentially the Gaussian process: a systematic association of vectors of arbitrary length with a suitable multi-variate normal distribution.

See also <https://jtimonen.github.io/lgpr-usage/articles/math.html>...

Low-rank approximate Gaussian processes are of main interest in machine learning and statistics due to the high computational demands of exact Gaussian process models [@riutort-mayol_practical_2023]...

-->
```

## Objectives

Focusing on identifying onset and offset of effects (as assessed by ERP differences or decoding performance)... Assessing the performance of a model-based approach (i.e., Bayesian GAMMs) to conventional methods (multiplicity corrections or cluster-based permutation)...

# Methods

## M/EEG data simulation

Following the approach used by @sassenhagen2019 and @rousselet_using_2025, we simulated EEG data stemming from two conditions, one with noise only, and the other with noise + signal. As in previous studies, the noise was generated by superimposing 50 sinusoids at different frequencies, following an EEG-like spectrum [see details and code in @yeung2004]. As in @rousselet_using_2025, the signal was generated from truncated Gaussian with an objective onset at 160 ms, a peak at 250 ms, and an offset at 342 ms. We simulated this signal for 250 timesteps between 0 and 0.5s, akin to a 500 Hz sampling rate. We simulated such data for a group of 20 participants with 50 trials per participant and condition (@fig-eeg).

```{r fig-eeg, echo = FALSE, fig.width = 9, fig.cap = "Averaged (mean) simulated EEG activity in two conditions with 50 trials each, for a group of 20 participants. The error band represents the mean plus/minus 1 standard error of the mean."}
# importing R version of Matlab code from Yeung et al. (2004)
source("code/eeg_noise.R")

# importing the ERP template with true onset = 160 ms, F=81, and max at F=126
source("code/erp_template.R")

# importing helper functions
source("code/functions.R")

# to use with the eeg_noise function
meanpower <- unlist(read.table("code/meanpower.txt") )

# defining simulation parameters
n_trials <- 50 # number of trials
n_ppt <- 20 # number of participants
outvar <- 1 # noise variance
srate <- 500 # sampling rate in Hz
ronset <- seq(from = 150, to = 170, by = 2) # random onset for each participant

# removing raw_df
if (exists("raw_df") ) rm(raw_df)

for (P in 1:n_ppt) { # for each participant
    
    # get random onset
    ponset <- sample(ronset, 1)
     
    # find starting point
    st <- which(Xf == ponset)
    
    # pad vector
    temp2 <- c(rep(0, st - 2), erp, rep(0, Nf - st - length(erp) + 2) )
    
    # initialising empty conditions
    cond1 <- matrix(0, nrow = n_trials, ncol = Nf)
    cond2 <- matrix(0, nrow = n_trials, ncol = Nf)
    
    for (T in 1:n_trials) { # for each trial
        
        cond1[T, ] <- temp1 + eeg_noise(frames = Nf, srate = srate, outvar = outvar, meanpower)
        cond2[T, ] <- temp2 + eeg_noise(frames = Nf, srate = srate, outvar = outvar, meanpower)
      
    }
    
    # converting results to dataframe
    temp_df <- data.frame(
        x = rep(Xf, 2*nrow(cond1) ),
        y = c(c(t(cond1) ), c(t(cond2) ) ),
        trial = c(rep(1:n_trials, each = length(Xf) ), rep(1:n_trials, each = length(Xf) ) ),
        condition = factor(rep(c("cond1", "cond2"), each = Nf * n_trials) ),
        participant = paste0("participant_", sprintf("%02d", P) )
        ) %>%
        select(participant, condition, trial, x, y)
    
    # and appending it to previous participants
    if (exists("raw_df") ) {
        
        raw_df <- bind_rows(raw_df, temp_df)
        
    } else {
        
        raw_df <- temp_df
        
    }
    
}

# converting time from ms to seconds
raw_df <- raw_df %>%
    # converting time from ms to seconds
    mutate(x = x / 1000) %>%
    # renaming columns
    rename(time = x, eeg = y)

# defining the true onset and offset in seconds
true_onset <- 0.160
true_peak <- 0.250
true_offset <- 0.342

# plotting the data
raw_df %>%
    summarise(
        eeg_mean = mean(eeg),
        eeg_se = sd(eeg) / sqrt(n() ),
        .by = c(participant, condition, time),
        ) %>%
    ggplot(aes(x = time, y = eeg_mean, colour = condition, fill = condition) ) +
    geom_hline(yintercept = 0, linetype = 2) +
    geom_vline(xintercept = true_onset, linetype = 2) +
    geom_vline(xintercept = true_offset, linetype = 2) +
    geom_ribbon(
        aes(ymin = eeg_mean - eeg_se, ymax = eeg_mean + eeg_se, colour = NULL),
        alpha = 0.3, show.legend = FALSE
        ) +
    geom_line(show.legend = FALSE) +
    facet_wrap(~participant) +
    scale_colour_met_d(name = "Johnson") +
    labs(x = "Time (s)", y = "EEG signal (a.u.)")
```

We computed the average of the ERP difference (@fig-erp)...

```{r fig-erp, echo = FALSE, out.width = "75%", fig.cap = "Group-level average difference between conditions (mean +/- standard error of the mean). The 'true' onset and offset are indicated by the vertical dashed lines."}
# averaging across participants
raw_df %>%
    pivot_wider(names_from = condition, values_from = eeg, values_fn = mean) %>%
    mutate(eeg_diff = cond2 - cond1) %>%
    summarise(
        eeg_mean = mean(eeg_diff),
        eeg_sem = sd(eeg_diff) / sqrt(n() ),
        .by = time
        ) %>%
    mutate(lower = eeg_mean - eeg_sem, upper = eeg_mean + eeg_sem) %>%
    # plotting the data
    ggplot(aes(x = time, y = eeg_mean) ) +
    geom_hline(yintercept = 0, linetype = 2) +
    geom_vline(xintercept = true_onset, linetype = 2) +
    geom_vline(xintercept = true_offset, linetype = 2) +
    geom_ribbon(
        aes(ymin = lower, ymax = upper, colour = NULL),
        alpha = 0.3, show.legend = FALSE
        ) +
    geom_line(show.legend = FALSE) +
    labs(x = "Time (s)", y = "EEG difference (a.u.)")
```

## Model fitting

We then fitted a Bayesian GAM using the `brms` package [@brms2017; @brms2018; @nalborczyk2019]. We used the default priors in `brms`, that is, weakly informative priors. We ran eight Markov Chain Monte-Carlo (MCMC) to approximate the posterior distribution, including each 5000 iterations and a warmup of 2000 iterations, yielding a total of $8 \times (5000-2000) = 24000$ posterior samples to use for inference. Posterior convergence was assessed examining trace plots as well as the Gelman–Rubin statistic $\hat{R}$. The `brms` package uses the same syntax as `r pkrt("mgcv")` for specifying smooth effects.

```{r gam, message = FALSE}
# averaging across participants
ppt_df <- raw_df %>%
    group_by(participant, condition, time) %>%
    summarise(eeg = mean(eeg) ) %>%
    ungroup()

# defining a contrast for condition
contrasts(ppt_df$condition) <- c(-0.5, 0.5)

# fitting the GAM
gam <- brm(
    # cubic regression splines with k-1 basis functions
    eeg ~ condition + s(time, bs = "cr", k = 10, by = condition),
    data = ppt_df,
    family = gaussian(),
    warmup = 2000,
    iter = 5000,
    chains = 8,
    cores = 8,
    file = "models/gam.rds"
    )
```

```{r gamm, echo = FALSE, eval = FALSE, message = FALSE}
# defining a contrast for condition
contrasts(raw_df$condition) <- c(-0.5, 0.5)

# fitting the GAMM with factor smooth (per participant)
gamm <- brm(
    # cubic regression splines with k-1 basis functions
    eeg ~ condition +
        s(time, bs = "cr", k = 10, by = condition) +
        s(time, participant, bs = "fs"),
    data = raw_df,
    family = gaussian(),
    warmup = 2000,
    iter = 5000,
    chains = 4,
    cores = 4,
    file = "models/gamm.rds"
    )
```

```{r gp, echo = FALSE, eval = FALSE, message = FALSE}
# Now we fit the GP regression model...
# computing eeg_diff and averaging across participants
# group_df <- raw_df %>%
#     group_by(participant, time) %>%
#     pivot_wider(names_from = condition, values_from = eeg, values_fn = mean) %>%
#     mutate(eeg_diff = cond2 - cond1) %>%
#     summarise(eeg_diff = mean(eeg_diff) ) %>%
#     ungroup()

# see https://betanalpha.github.io/assets/case_studies/gp_part3/part3.html
# and https://betanalpha.github.io/assets/case_studies/gaussian_processes.html
gp_priors <- c(
    set_prior("normal(0, 1)", class = "Intercept"),
    set_prior("normal(0, 1)", class = "b"),
    set_prior("exponential(1)", class = "sigma"),
    set_prior("exponential(1)", class = "sdgp")
    )

gp_model <- brm(
    # k refers to the number of basis functions for
    # computing Hilbert-space approximate GPs
    # if k = NA (default), exact GPs are computed
    # eeg ~ gp(time, by = condition),
    eeg ~ condition + gp(time, by = condition, k = 20, cov = "exp_quad"),
    data = ppt_df,
    family = gaussian(),
    # prior = gp_priors,
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    backend = "cmdstanr",
    iter = 2000,
    chains = 4,
    cores = 4,
    file = "models/gp.rds"
    )
```

```{r model-preds, echo = FALSE}
# defining a function to plot posterior predictions
plot_post_preds <- function (model, data = NULL) {
    
    if (is.null(data) ) data <- model$data
    
    post_preds <- conditional_effects(
        x = model,
        effect = "time:condition",
        method = "posterior_epred",
        re_formula = NULL,
        prob = 0.99
        )[[1]]
  
    post_preds %>%
        ggplot(aes(x = time, y = eeg, colour = condition, fill = condition) ) +
        geom_vline(xintercept = true_onset, linetype = 2) +
        geom_vline(xintercept = true_offset, linetype = 2) +
        geom_hline(yintercept = 0, linetype = 2) +
        geom_point(
            data = data %>% summarise(eeg = mean(eeg), .by = c(time, condition) ),
            aes(fill = NULL),
            pch = 21, show.legend = FALSE
            ) +
        geom_line(aes(y = estimate__), show.legend = FALSE) +
        geom_ribbon(
            aes(ymin = lower__, ymax = upper__, colour = NULL),
            alpha = 0.25, show.legend = FALSE
            ) +
        scale_colour_met_d(name = "Johnson") +
        scale_fill_met_d(name = "Johnson") +
        labs(x = "Time (s)", y = "EEG signal (a.u.)")
    
}
```

```{r gam-preds, echo = FALSE, eval = FALSE, fig.width = 8, fig.asp = 0.5, fig.cap = "Posterior predictions of the GAM (left) and GP (right) models."}
# plotting the posterior predictions
plot_post_preds(model = gam) + plot_post_preds(model = gp_model)
```

## Posterior probability of difference above 0

We then plot the posterior predictions together with the posterior estimate of the slope for `condition` at each timestep (@fig-plot-post-slope).

```{r fig-plot-post-slope, echo = FALSE, fig.width = 8, fig.asp = 0.5, fig.cap = "Posterior estimate of the ERP in each condition (left) or directly for the difference of ERPs (right) according to the GAM."}
# defining a function to plot posterior slope
plot_post_slope <- function (model, data = NULL) {
  
    # if no data is specified, use model$data
    if (is.null(data) ) data <- model$data
    
    # defining a sequence of time values to make predictions
    time_seq <- crossing(
        time = seq(min(data$time), max(data$time), length.out = 100),
        condition = c("cond1", "cond2")
        ) %>%
        arrange(condition)
    
    # retrieving posterior samples
    posterior_samples <- posterior_epred(object = model, newdata = time_seq)
    
    # computing the difference between cond2 and cond1
    posterior_samples <- posterior_samples[, 101:200] - posterior_samples[, 1:100] 
    
    # computing the probability that y is above 0
    prob_y_above_0 <- data.frame(
        time = seq(min(data$time), max(data$time), length.out = 100)
        ) %>%
        mutate(
          m = colMeans(posterior_samples),
          lower = apply(
              X = posterior_samples,
              MARGIN = 2, FUN = quantile, probs = 0.025
              ),
          upper = apply(
              X = posterior_samples,
              MARGIN = 2, FUN = quantile, probs = 0.975
              )
          )
    
    # plotting it
    prob_y_above_0 %>%
        ggplot(aes(x = time, y = m) ) +
        geom_hline(yintercept = 0, linetype = 2) +
        geom_vline(xintercept = true_onset, linetype = 2) +
        geom_vline(xintercept = true_offset, linetype = 2) +
        geom_line() +
        geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
        scale_colour_met_d(name = "Johnson") +
        scale_fill_met_d(name = "Johnson") +
        labs(
            x = "Time (s)",
            y = expression(p(beta~"|"~data, model) )
            )
  
}

# plotting it
# plot_post_slope(model = gam, eps = 0.1) + plot_post_slope(model = gp_model, eps = 0.1)
plot_post_preds(model = gam) + plot_post_slope(model = gam)
```

We then compute the posterior probability of the slope for `condition` being above $0+\epsilon$ (@fig-post-prob-test), with $\epsilon := 0.05$, which can be interpreted as the smallest effect size of interest.

```{r fig-post-prob-test, echo = FALSE, out.width = "75%", fig.asp = 0.75, fig.cap = "Posterior probability of the ERP difference (slope) being above 0 according to the GAM."}
# defining a function to plot posterior prob of slope above 0
plot_post_test <- function (model, data = NULL, eps = 0.1, n_approx = 1e3, n_draws = 1e3) {
    
    # if no data is specified, use model$data
    if (is.null(data) ) data <- model$data
    
    # defining a sequence of time values to make predictions
    time_seq <- crossing(
        time = seq(min(data$time), max(data$time), length.out = n_approx),
        # time = unique(data$time),
        condition = c("cond1", "cond2")
        ) %>%
        arrange(condition)
    
    # retrieving posterior samples
    # posterior_samples <- posterior_epred(object = model, newdata = time_seq)
    
    # computing the difference between cond2 and cond1
    # posterior_samples <- posterior_samples[, (nrow(time_seq)/2+1):nrow(time_seq)] -
    #     posterior_samples[, 1:(nrow(time_seq)/2)]
    
    # computing the probability that y is above 0
    # prob_y_above_0 <- data.frame(
    #     time = time_seq$time,
    #     m = colMeans(posterior_samples > (0 + eps) )
    #     )
    
    # computing probability metrics with the current eps value
    prob_y_above_0 <- time_seq %>%
        add_epred_draws(object = model, ndraws = n_draws) %>%
        data.frame() %>%
        dplyr::select(time, condition, .epred, .draw) %>%
        pivot_wider(names_from = condition, values_from = .epred) %>%
        mutate(epred_diff = cond2 - cond1) %>%
        group_by(time) %>%
        summarise(m = mean(epred_diff > 0 + eps) ) %>%
        ungroup()
        
    # plotting it
    prob_y_above_0 %>%
        ggplot(aes(x = time, y = m) ) +
        geom_hline(yintercept = 0.5, linetype = 2) +
        geom_vline(xintercept = true_onset, linetype = 2) +
        geom_vline(xintercept = true_offset, linetype = 2) +
        geom_line() +
        ylim(c(0, 1) ) +
        labs(x = "Time (s)", y = expression(Pr(beta>0~"|"~data, model) ) )
  
}

# using the function with the two models
plot_post_test(model = gam, eps = 0.1)
```

We can also express this as the ratio of posterior probabilities (i.e., $p/(1-p)$) and visualise the timecourse of this ratio superimposed with the conventional thresholds on evidence ratios (@fig-post-prob-ratio).

```{r fig-post-prob-ratio, echo = FALSE, out.width = "75%", fig.asp = 0.75, fig.cap = "Ratio of posterior probability according to the GAM. Timesteps above threshold (10) are highlighted in green."}
# defining some parameters
n_approx <- 1e3
eps <- 0.05
threshold <- 10

# defining a sequence of x values to make predictions
time_seq <- crossing(
    time = seq(min(ppt_df$time), max(ppt_df$time), length.out = n_approx),
    # time = unique(ppt_df$time),
    condition = c("cond1", "cond2")
    ) %>%
    arrange(condition)

# computing the posterior probability that y is above 0
n_posterior_samples <- 24000
prob_y_above_0 <- time_seq %>%
    add_epred_draws(object = gam) %>%
    data.frame() %>%
    dplyr::select(time, condition, .epred, .draw) %>%
    pivot_wider(names_from = condition, values_from = .epred) %>%
    mutate(epred_diff = cond2 - cond1) %>%
    group_by(time) %>%
    summarise(m = mean(epred_diff > 0 + eps) ) %>%
    ungroup() %>%
    mutate(prob_ratio = m / (1 - m) ) %>%
    # replacing infinite values by maximum possible values (number of posterior samples)
    mutate(prob_ratio = ifelse(is.infinite(prob_ratio), n_posterior_samples, prob_ratio) ) %>%
    mutate(prob_ratio = ifelse(prob_ratio == 0, 1/n_posterior_samples, prob_ratio) )

# printing the identified clusters
# the signal was a truncated Gaussian defining an objective onset at 160 ms,
# a maximum at 250 ms, and an offset at 342 ms.
# exceeding_times_gam <- prob_y_above_0 %>%
#     dplyr::filter(prob_ratio > threshold) %>%
#     summarise(cluster_onset = min(time), cluster_offset = max(time) ) %>%
#     # mutate(
#     #     cluster_peak = prob_y_above_0 %>%
#     #         dplyr::filter(post_prob == max(post_prob) ) %>%
#     #         pull(time)
#     #     ) %>%
#     # mutate(true_onset = true_onset, true_peak = true_peak, true_offset = true_offset) %>%
#     mutate(true_onset = true_onset, true_offset = true_offset) %>%
#     mutate(model = "GAM")

# creating a grid covering the range of time and log-transformed y-values
bg_data <- expand.grid(
    time = seq(min(prob_y_above_0$time), max(prob_y_above_0$time), length.out = 100),
    # prob_ratio = 10^seq(log10(0.0001), log10(1e4), length.out = 100)
    prob_ratio = 10^seq(log10(min(prob_y_above_0$prob_ratio) ), log10(max(prob_y_above_0$prob_ratio) ), length.out = 100)
    )

# assigning a fill value, for example, using prob_ratio or another variable
bg_data$fill_value <- log10(bg_data$prob_ratio)

# plotting it
gam_ratio_plot <- prob_y_above_0 %>%
    mutate(above_thres = ifelse(prob_ratio > threshold, 1, NA) ) %>%
    ggplot(aes(x = time, y = prob_ratio) ) +
    geom_raster(
        data = bg_data,
        aes(x = time, y = prob_ratio, fill = fill_value),
        alpha = 0.5,
        interpolate = FALSE,
        inherit.aes = FALSE,
        show.legend = FALSE
        ) +
    scale_fill_scico(palette = "vik", midpoint = log10(1) ) +
    geom_hline(yintercept = 1, linetype = "dashed") +
    geom_hline(yintercept = 3, linetype = "dashed", color = "darkred") +
    geom_hline(yintercept = 1/3, linetype = "dashed", color = "darkred") +
    geom_hline(yintercept = 10, linetype = "dashed", color = "red") +
    geom_hline(yintercept = 1/10, linetype = "dashed", color = "red") +
    geom_hline(yintercept = 100, linetype = "dashed", color = "orangered") +
    geom_hline(yintercept = 1/100, linetype = "dashed", color = "orangered") +
    geom_vline(xintercept = true_onset, linetype = 2) +
    geom_vline(xintercept = true_offset, linetype = 2) +
    geom_line(linewidth = 0.8) +
    geom_point(
        data = . %>% dplyr::filter(!is.na(above_thres) ),
        aes(y = threshold),
        colour = "darkgreen",
        shape = 16,
        size = 3,
        na.rm = TRUE
        ) +
    scale_y_log10(
        labels = label_log(digits = 2),
        breaks = c(1/1e4, 1/1e3, 1/1e2, 1/10, 1, 10, 1e2, 1e3, 1e4)
        # limits = c(0.0001, 1e4)
        ) +
    coord_cartesian(expand = FALSE) +
    labs(
        x = "Time (s)",
        y = expression(Pr(beta>0~"|"~data) / (1 - Pr(beta>0~"|"~data) ) )
        )

# retrieving posterior samples
# posterior_samples <- posterior_epred(object = gp_model, newdata = time_seq)

# computing the difference between cond2 and cond1
# posterior_samples <- posterior_samples[, (ncol(posterior_samples)/2+1):ncol(posterior_samples)] -
#     posterior_samples[, 1:(ncol(posterior_samples)/2)]

# computing the probability that y is above 0
# prob_y_above_0 <- data.frame(
#     time = seq(min(ppt_df$time), max(ppt_df$time), length.out = n_approx)
#     ) %>%
#     mutate(post_prob = colMeans(posterior_samples) ) %>%
#     mutate(m = colMeans(posterior_samples > eps) ) %>%
#     mutate(prob_ratio = m / (1 - m) )

# printing the identified clusters
# the signal was a truncated Gaussian defining an objective onset at 160 ms,
# a maximum at 250 ms, and an offset at 342 ms
# exceeding_times_gp <- prob_y_above_0 %>%
#     dplyr::filter(prob_ratio > threshold) %>%
#     summarise(cluster_onset = min(time), cluster_offset = max(time) ) %>%
#     mutate(
#         cluster_peak = prob_y_above_0 %>%
#             dplyr::filter(post_prob == max(post_prob) ) %>%
#             pull(time)
#         ) %>%
#     mutate(true_onset = true_onset, true_peak = true_peak, true_offset = true_offset) %>%
#     mutate(model = "GP")

# plotting it
# gp_ratio_plot <- prob_y_above_0 %>%
#     mutate(above_thres = ifelse(prob_ratio > threshold, 1, NA) ) %>%
#     ggplot(aes(x = time, y = prob_ratio) ) +
#     geom_hline(yintercept = 1, linetype = "dashed") +
#     geom_hline(yintercept = 3, linetype = "dashed", color = "darkred") +
#     geom_hline(yintercept = 1/3, linetype = "dashed", color = "darkred") +
#     geom_hline(yintercept = 10, linetype = "dashed", color = "red") +
#     geom_hline(yintercept = 1/10, linetype = "dashed", color = "red") +
#     geom_hline(yintercept = 100, linetype = "dashed", color = "orangered") +
#     geom_hline(yintercept = 1/100, linetype = "dashed", color = "orangered") +
#     geom_vline(xintercept = true_onset, linetype = 2) +
#     geom_vline(xintercept = true_offset, linetype = 2) +
#     geom_line() +
#     geom_point(
#         data = . %>% dplyr::filter(!is.na(above_thres) ),
#         aes(y = threshold),
#         colour = "darkgreen",
#         shape = 15,
#         size = 3,
#         na.rm = TRUE
#         ) +
#     scale_y_log10(labels = label_log(digits = 2), limits = c(NA, 1e4) ) +
#     labs(
#         x = "Time (s)",
#         y = expression(Pr(beta>0~"|"~data) / (1 - Pr(beta>0~"|"~data) ) )
#         )

# plotting results for the two models
# gam_ratio_plot + gp_ratio_plot

# or plotting only the GAM
gam_ratio_plot

# printing the results
# bind_rows(exceeding_times_gam, exceeding_times_gp) %>%
#     mutate(across(.cols = where(is.numeric), .fns = ~round(.x, 2) ) ) %>%
#     relocate(model, .before = cluster_onset)
```

\newpage

## Multilevel modelling using ERP summary statistics

Next we fit a hierarchical/multilevel GAM using summary statistics of ERPs (mean and SD) at the participant level (similar to what is done in meta-analysis).

```{r meta-gam, message = FALSE}
# averaging across participants
summary_df <- raw_df %>%
    summarise(
        eeg_mean = mean(eeg),
        eeg_sd = sd(eeg),
        .by = c(participant, condition, time)
        )

# defining a contrast for condition
contrasts(summary_df$condition) <- c(-0.5, 0.5)

# fitting the GAM
meta_gam <- brm(
    # using by-participant SD of ERPs across trials
    eeg_mean | se(eeg_sd) ~
        condition + s(time, bs = "cr", k = 10, by = condition) +
        (1 | participant),
    data = summary_df,
    family = gaussian(),
    warmup = 2000,
    iter = 5000,
    chains = 8,
    cores = 8,
    file = "models/meta_gam.rds"
    )
```

```{r meta-gp, echo = FALSE, eval = FALSE, message = FALSE}
# fitting the GP
meta_gp <- brm(
    # using by-participant SD of ERPs across trials
    eeg_mean | se(eeg_sd) ~
        condition + gp(time, k = 20, by = condition) +
        (1 | participant),
    data = summary_df,
    family = gaussian(),
    control = list(adapt_delta = 0.99),
    iter = 5000,
    chains = 4,
    cores = 4,
    file = "models/meta_gp.rds"
    )
```

```{r meta-preds, echo = FALSE, fig.width = 9, fig.asp = 0.5, fig.cap = "Posterior predictions for the hierarchical GAM."}
# plotting the posterior predictions
meta_gam_preds <- plot(
    conditional_effects(x = meta_gam, effect = "time:condition"),
    points = FALSE, theme = theme_light(), plot = FALSE
    )[[1]] +
    scale_colour_met_d(name = "Johnson") +
    scale_fill_met_d(name = "Johnson") +
    labs(x = "Time (s)", y = "EEG signal (a.u.)")
# meta_gp_preds <- plot(
#     conditional_effects(x = meta_gp, effect = "time:condition"),
#     points = FALSE, theme = theme_light(), plot = FALSE
#     )[[1]] +
#     scale_colour_met_d(name = "Johnson") +
#     scale_fill_met_d(name = "Johnson") +
#     labs(x = "Time (s)", y = "EEG signal (a.u.)")

# combining the two plots
# meta_gam_preds + meta_gp_preds
```

## Error properties of the proposed approach

We then computed the difference between the true and estimated onset/offset of the ERP difference ($\text{error}:=|\hat{\theta}-\theta|$), according to various `eps` and `threshold` values. Remember that the signal is generated from a truncated Gaussian with an objective onset at 160 ms, a maximum at 250 ms, and an offset at 342 ms. @fig-onset-error shows that the hierarchical GAM can *exactly* recover the true onset and offset values, given some reasonable choice of `eps` and `threshold` values (e.g., a threshold of 20).

```{r fig-onset-error, echo = FALSE, dpi = 300, fig.width = 8, fig.asp = 0.5, fig.cap = "Error function of onset (left) and offset (right) estimation according to various eps and threshold values (according to the hierarchical GAM). Minimum error values are indicated by red crosses."}
# defining values of eps and threshold to test
eps_values <- seq(from = 0, to = 0.1, by = 0.01)
threshold_values <- seq(from = 1, to = 30, by = 1)

# using as many values of time as in the original data
# n_approx <- n_distinct(ppt_df$time)

# number of posterior samples to use
n_post_samples <- 1e3

# initialising results dataframe
results <- crossing(eps = eps_values, threshold = threshold_values) %>%
    mutate(
        estimated_onset = NA, estimated_peak = NA, estimated_offset = NA,
        error_onset = NA, error_peak = NA, error_offset = NA
        )

# which model should we use?
error_model <- meta_gam

# generating a grid of time values to compute predictions for
# time_seq <- crossing(
#     condition = c("cond1", "cond2"),
#     time = seq(min(ppt_df$time), max(ppt_df$time), length.out = n_approx*2-1),
#     ) %>%
#     arrange(condition)

# eps <- 0.05
# preds <- meta_gam$data %>%
#     add_epred_draws(meta_gam, ndraws = 1e3) %>%
#     data.frame() %>%
#     dplyr::select(participant, time, condition, .epred, .draw) %>%
#     group_by(participant, time) %>%
#     pivot_wider(names_from = condition, values_from = .epred) %>%
#     mutate(epred_diff = cond2 - cond1) %>%
#     summarise(m = mean(epred_diff > eps) ) %>%
#     mutate(prob_ratio = m / (1 - m) ) %>%
#     ungroup()

# plotting these predictions
# preds %>%
#     ggplot(aes(x = time, y = m) ) +
#     geom_line() +
#     facet_wrap(~participant)

# retrieving posterior samples
# posterior_samples <- posterior_epred(object = gp_model, newdata = time_seq)
# posterior_samples <- posterior_epred(object = gam, newdata = time_seq)
# library(modelr)
# meta_gam$data %>%
#     add_epred_draws(meta_gam, ndraws = 20, re_formula = NA) %>%
#     ggplot(
#         aes(
#             x = time, y = .epred,
#             colour = condition,
#             group = interaction(participant, condition, .draw)
#             )
#         ) +
#     geom_hline(yintercept = 0, linetype = 2) +
#     geom_vline(xintercept = true_onset, linetype = 2) +
#     geom_vline(xintercept = true_offset, linetype = 2) +
#     geom_line(show.legend = TRUE, alpha = 0.5, linewidth = 0.5) +
#     facet_wrap(~participant) +
#     labs(x = "Time (s)", y = "EEG signal (a.u.)")

# computing the difference between cond2 and cond1
# posterior_samples <- posterior_samples[, (ncol(posterior_samples)/2):ncol(posterior_samples)] -
#     posterior_samples[, 1:(ncol(posterior_samples)/2+1)]

# looping over different values of eps and threshold
for (i in seq_len(nrow(results) ) ) {
    
    # printing progress
    # cat("Assessing combination:", i, "out of", nrow(results), "combinations...")
    
    # retrieving current eps and threshold values
    eps <- results$eps[i]
    threshold <- results$threshold[i]
    
    # computing probability metrics with the current eps value
    # prob_y_above_0 <- data.frame(
    #     time = seq(min(ppt_df$time), max(ppt_df$time), length.out = n_approx*2-1)
    #     ) %>%
    # mutate(post_prob = colMeans(posterior_samples) ) %>%
    # mutate(m = colMeans(posterior_samples > eps) ) %>%
    # mutate(prob_ratio = m / (1 - m) )
    
    prob_y_above_0 <- error_model$data %>%
        add_epred_draws(object = error_model, ndraws = n_post_samples) %>%
        data.frame() %>%
        dplyr::select(participant, time, condition, .epred, .draw) %>%
        # dplyr::select(time, condition, .epred, .draw) %>%
        pivot_wider(names_from = condition, values_from = .epred) %>%
        mutate(epred_diff = cond2 - cond1) %>%
        # computing mean posterior prob at the participant level
        group_by(participant, time) %>%
        summarise(m = mean(epred_diff > eps) ) %>%
        ungroup() %>%
        # computing mean posterior prob at the group level
        group_by(time) %>%
        summarise(m = mean(m) ) %>%
        mutate(prob_ratio = m / (1 - m) ) %>%
        ungroup()
    
    # finding onset, offset, and peak for the current threshold
    exceeding_times <- prob_y_above_0 %>%
        dplyr::filter(prob_ratio > threshold) %>%
        summarise(
            cluster_onset = min(time, na.rm = TRUE),
            cluster_offset = max(time, na.rm = TRUE)
            ) %>%
        # mutate(
        #     cluster_peak = prob_y_above_0 %>%
        #     dplyr::filter(post_prob == max(post_prob, na.rm = TRUE) ) %>%
        #     pull(time)
        #     ) %>%
        # mutate(true_onset = true_onset, true_peak = true_peak, true_offset = true_offset)
        mutate(true_onset = true_onset, true_offset = true_offset)
    
    # storing the results in the dataframe
    if (nrow(exceeding_times) > 0) {
        
        results$estimated_onset[i] <- exceeding_times$cluster_onset
        # results$estimated_peak[i] <- exceeding_times$cluster_peak
        results$estimated_offset[i] <- exceeding_times$cluster_offset
        
        # computing errors
        results$error_onset[i] <- abs(
            exceeding_times$cluster_onset - exceeding_times$true_onset
            )
        # results$error_peak[i] <- abs(
        #     exceeding_times$cluster_peak - exceeding_times$true_peak
        #     )
        results$error_offset[i] <- abs(
            exceeding_times$cluster_offset - exceeding_times$true_offset
            )
        
    }
    
}

# plotting the results
onset_plot <- results %>%
    ggplot(aes(x = eps, y = threshold, fill = error_onset) ) +
    geom_tile(show.legend = FALSE) +
    geom_point(
        data = results %>% dplyr::filter(error_onset == min(error_onset, na.rm = TRUE) ),
        aes(x = eps, y = threshold),
        color = "orangered", size = 2, shape = 4,
        show.legend = FALSE
        ) +
    scale_x_continuous(expand = c(0, 0) ) +
    scale_y_continuous(expand = c(0, 0) ) +
    scale_fill_gradientn(colors = rev(met.brewer("Hokusai1") ) ) +
    labs(
        title = "Onset error",
        x = "eps",
        y = "Threshold",
        fill = "Error"
        )

offset_plot <- results %>%
    ggplot(aes(x = eps, y = threshold, fill = error_offset) ) +
    geom_tile(show.legend = FALSE) +
    geom_point(
        data = results %>% dplyr::filter(error_offset == min(error_offset, na.rm = TRUE) ),
        aes(x = eps, y = threshold),
        color = "orangered", size = 2, shape = 4,
        show.legend = FALSE
        ) +
    scale_x_continuous(expand = c(0, 0) ) +
    scale_y_continuous(expand = c(0, 0) ) +
    scale_fill_gradientn(colors = rev(met.brewer("Hokusai1") ) ) +
    labs(
        title = "Offset error",
        x = "eps",
        y = "Threshold",
        fill = "Error"
        )

# combining the plots
onset_plot + offset_plot

# displaying best parameters values (according to onset error)
# results %>%
#     dplyr::select(-estimated_peak, -error_peak) %>%
#     arrange(error_onset) %>%
#     data.frame() %>%
#     head()

# displaying best parameters values (according to offset error)
# results %>%
#     dplyr::select(-estimated_peak, -error_peak) %>%
#     arrange(error_offset) %>%
#     data.frame() %>%
#     head()

# displaying best parameters values (according to both onset and offset error)
results %>%
    dplyr::select(-estimated_peak, -error_peak) %>%
    arrange(error_onset, error_offset) %>%
    data.frame() %>%
    head()
```

\newpage

## Comparing the identified onsets/offsets to other approaches

We compared the ability of the GAMM to correctly estimate the onset and offset of the ERP difference to widely used methods. First, we conducted mass-univariate t-tests (thus treating each timestep independently) and identified the onset and offset of the ERP difference as the first and last values crossing an arbitrary significance threshold ($\alpha = 0.01$). We then followed the same approach but after applying different forms of multiplicity correction the the p-values. We compared two methods that control the false discovery rate (FDR) [i.e., BH95, @benjamini1995; and BY01, @benjamini2001], one method that controls the familywise error rate (FWER) [i.e., Holm–Bonferroni method, @holm1979], and two cluster-based methods [permutation with a single threshold and TFCE, @smith2009]. The BH95, BY01, and Holm corrections were applied to the p-values using the `p.adjust()` function in `R`. The cluster-based inference was implemented using a cluster-sum statistic of squared t-values, as implemented in `MNE-Python` [@gramfort2013], called via `r pkrt("reticulate")`. We also compared these estimates to the onset and offset as estimated using the binary segmentation algorithm, as implemented in `r pkrt("changepoint")`, and applied directly to the squared t-values [as in @rousselet_using_2025]. For visualisation and interpretability purposes, we converted p-values to s-values, which can be interpreted as bits of surprising information, assuming a null effect [@greenland2019] (@fig-corrections).

```{r permutations-1d, echo = FALSE, eval = FALSE, fig.cap = "T-values timecourse with onset identified using the permuco package (clustermass method)."}
# centering AUC relative to chance level (0.5)
decoding_data_perm <- decoding_data %>%
    mutate(auc_centered = auc - 0.5) %>%
    dplyr::select(-auc)

# formatting the AUC data to be used with permuco
dv <- decoding_data_perm %>%
    pivot_wider(names_from = time, values_from = auc_centered) %>%
    dplyr::select(-participant) %>%
    data.frame()

# formatting the intercept to be used with permuco
iv <- decoding_data %>%
    dplyr::select(participant) %>%
    distinct() %>%
    mutate(participant = as.factor(participant) ) %>%
    data.frame() %>%
    mutate(intercept = 1)

# performing cluster-based permutation test
cluster_results <- clusterlm(
    formula = dv ~ intercept,
    data = iv,
    # data = decoding_data_perm,
    # formula = auc_centered ~ participant,
    # number of permutations (increase for accuracy)
    # np = 2000,
    # type of transformation
    type = "signflip"
    # using a t-test
    # test = "t"
    # multiple comparison correction
    # multcomp = "clustermass"
    # multcomp = "clusterdepth_head",
    # multcomp = "tfce"
    )

# printing results
print(cluster_results)

# plotting significant clusters
plot(cluster_results)

# retrieving t and p-values
f_values <- cluster_results$multiple_comparison$intercept$clustermass$main[, 1]
p_values <- cluster_results$multiple_comparison$intercept$clustermass$main[, 2]
```

```{r fig-corrections, echo = FALSE, fig.width = 9, fig.asp = 0.5, fig.cap = "Timecourse of squared t-values and s-values, with true onset (black dashed line) and onsets identified using the raw (uncorrected) p-values or the corrected p-values (BH, BY, Holm)."}
# defining an arbitrary alpha threshold
aath <- 0.01

# summarising raw_data per participant
ppt_data <- raw_df %>%
    summarise(eeg = mean(eeg), .by = c(participant, condition, time) ) %>%
    pivot_wider(names_from = condition, values_from = eeg) %>%
    mutate(eeg_diff = cond2 - cond1)

# massive univariate t-tests
tests_results <- ppt_data %>%
    group_by(time) %>%
    summarise(
        tval = t.test(x = eeg_diff, mu = 0)$statistic^2,
        pval = t.test(x = eeg_diff, mu = 0)$p.value
        ) %>%
    mutate(
        pval_bh = p.adjust(p = pval, method = "BH"),
        pval_by = p.adjust(p = pval, method = "BY"),
        pval_holm = p.adjust(p = pval, method = "holm")
        ) %>%
    ungroup()

# finding onsets
from_timestep <- 1
onset_p <- find_onset(
    tests_results$pval[from_timestep:nrow(tests_results)] <= aath,
    tests_results$time[from_timestep:nrow(tests_results)]
    )
onset_bh <- find_onset(
    tests_results$pval_bh[from_timestep:nrow(tests_results)] <= aath,
    tests_results$time[from_timestep:nrow(tests_results)]
    )
onset_by <- find_onset(
    tests_results$pval_by[from_timestep:nrow(tests_results)] <= aath,
    tests_results$time[from_timestep:nrow(tests_results)]
    )
onset_holm <- find_onset(
    tests_results$pval_holm[from_timestep:nrow(tests_results)] <= aath,
    tests_results$time[from_timestep:nrow(tests_results)]
    )

# plotting the results
default_colours <- met.brewer(name = "Johnson", n = 4)
tvals_plot <- tests_results %>%
    ggplot(aes(x = time, y = tval) ) +
    geom_area(position = "identity") +
    geom_vline(xintercept = true_onset, linetype = 2) +
    geom_vline(xintercept = onset_p, linetype = 2, color = default_colours[1]) +
    geom_vline(xintercept = onset_bh, linetype = 2, color = default_colours[2]) +
    geom_vline(xintercept = onset_by, linetype = 2, color = default_colours[3]) +
    geom_vline(xintercept = onset_holm, linetype = 2, color = default_colours[4]) +
    labs(x = "Time (s)", y = bquote(t^2) )

plot_title <- paste0(
    "True onset: ", true_onset, "s, ",
    "Uncorrected onset: ", round(onset_p, 3), "s, ",
    "BH onset: ", round(onset_bh, 3), "s, ",
    "BY onset: ", round(onset_by, 3), "s, ",
    "Holm onset: ", round(onset_holm, 3),  "s"
    )

# plotting -log2(p) (surprisal under H0) with thresholds (on p-values)
# https://lesslikely.com/statistics/s-values/
# a s-value of 4 (bits of information) is no more surprising than
# getting all heads on 4 fair coin tosses
pvals_plot <- tests_results %>%
    pivot_longer(cols = pval:pval_holm) %>%
    mutate(sval = -log2(value) ) %>%
    ggplot(aes(x = time, y = sval, colour = name) ) +
    geom_line(linewidth = 0.5) +
    geom_hline(yintercept = -log2(aath), linetype = 2) +
    geom_vline(xintercept = true_onset, linetype = 2) +
    geom_vline(xintercept = onset_p, linetype = 2, color = default_colours[1]) +
    geom_vline(xintercept = onset_bh, linetype = 2, color = default_colours[2]) +
    geom_vline(xintercept = onset_by, linetype = 2, color = default_colours[3]) +
    geom_vline(xintercept = onset_holm, linetype = 2, color = default_colours[4]) +
    scale_colour_manual(values = met.brewer(name = "Johnson", n = 4) ) +
    labs(
        x = "Time (s)",
        y = "-log2(p-value)",
        colour = "correction"
        )

# combining the two plots
tvals_plot + pvals_plot +
    plot_annotation(title = plot_title) & theme(plot.title = element_text(hjust = 0.5) )
```

```{r changepoint, echo = FALSE, eval = FALSE, out.width = "75%", fig.cap = "T-values timecourse with true onset/offset and onset/offset identified using the changepoint package (binary segmentation method, in green)."}
# using the changepoint package to identify onsets and offsets
res <- cpt.meanvar(data = tests_results$tval, method = "BinSeg", Q = 2)

# plotting the results
tests_results %>%
    ggplot(aes(x = time, y = tval) ) +
    geom_line(linewidth = 1) +
    geom_vline(xintercept = true_onset, linetype = 2) +
    geom_vline(xintercept = true_offset, linetype = 2) +
    geom_vline(
        xintercept = tests_results$time[res@cpts[1]],
        linetype = 3, color = "darkgreen"
        ) +
    geom_vline(
        xintercept = tests_results$time[res@cpts[2]],
        linetype = 3, color = "darkgreen"
        ) +
    labs(x = "Time (s)", y = bquote(t^2) ) +
    ggtitle(
        paste0(
            "True onset: ", true_onset, "s, ", "Change point onset: ",
            round(tests_results$time[res@cpts[1]], 3), "s, ",
            "True offset: ", true_offset, "s, ", "Change point offset: ",
            round(tests_results$time[res@cpts[2]], 3), "s"
            )
        )
```

```{r mne-cluster, echo = FALSE, eval = FALSE, fig.cap = "Cluster-based permutation tests via MNE-Python."}
# loading the reticulate package
library(reticulate)

# importing the numpy and mne python modules
np <- import("numpy")
mne <- import("mne")

# defining the function in R (it will be executed in Python)
freq_stats_gat_matrix <- function (X) {
    
    # converting R matrix to NumPy array
    X_np <- np$array(X, dtype = "float64")
    
    # running the statistical test
    results <- mne$stats$spatio_temporal_cluster_1samp_test(
        X_np,
        out_type = "mask",
        n_permutations = as.integer(1000),
        n_jobs = as.integer(4),
        verbose = TRUE
        )
    
    # extracting results
    T_obs_ <- results[[1]]
    clusters <- results[[2]]
    p_values <- results[[3]]
    
    # using the first slice of the 3D array
    p_values_ <- np$transpose(np$ones_like(X_np[1, , drop = FALSE]) )
    
    # assigning p-values to clusters
    for (i in seq_along(clusters) ) {
        
        # retrieving the current cluster
        cluster_mask <- clusters[[i]][[1]]
        idx_start <- cluster_mask$start+1
        idx_stop <- cluster_mask$stop
        
        # retrieving the p-value for this cluster
        pval <- p_values[[i]]
        
        # assigning this p-value to timesteps belonging
        # to the current cluster
        p_values_[idx_start:idx_stop] <- pval
        
    }
    
    # converting result back to R format
    return (as.matrix(np$squeeze(np$transpose(p_values_) ) ) )
    
}

# converting decoding_data to a matrix
data_matrix <- matrix(
    decoding_data$auc,
    ncol = length(unique(decoding_data$time) ),
    byrow = TRUE
    )

# running the function
chance_level <- 0.5
p_values_results <- freq_stats_gat_matrix(data_matrix-chance_level)

# converting back to a dataframe if needed
p_values_df <- data.frame(
    pval = p_values_results,
    time = decoding_data$time
    )

# saving the scores
saveRDS(object = p_values_df, file = "results/mne_permutation_decoding_scores.rds")
```

```{r fig-mne-cluster, echo = FALSE, eval = FALSE, out.width = "75%", fig.cap = "Cluster-based permutation tests via MNE-Python."}
# importing the decoding scores
p_values_df <- readRDS(file = "results/mne_permutation_decoding_scores.rds")

# plotting the s-values (-log2(p-values))
p_values_df %>%
    mutate(sval = -log2(pval) ) %>%
    ggplot(aes(x = time, y = sval) ) +
    geom_line(linewidth = 0.5) +
    geom_hline(yintercept = -log2(0.05), linetype = 2) +
    labs(
        x = "Time (s)",
        y = "-log2(p-value)"
        )
```

\newpage

## Simulation study

Onset/offset estimation methods were assessed using the median absolute error (MAE) and variance of 10.000 simulated datasets...

## Application to actual MEG data

Assessing the reliability of the proposed approach using some sort of split-half reliability [e.g., @rosenblatt2018]? Using the MEG decoding results of Nalborczyk et al. (in preparation) in 33 participants:

-   Create many (e.g., 10 or 20) half train/test splits of the data
-   For each fold, estimate the onset/offset on both splits using all methods
-   Then summarise the distribution of onset/offset with the median and variance across folds

This will allow checking that the proposed approach produces reliable onset/offset estimates.

```{r reliability, echo = FALSE, eval = FALSE}
# library(caret)
# see https://github.com/topepo/caret/
# https://topepo.github.io/caret/data-splitting.html
# and createDataPartition()
# and createFolds()
# trainIndex <- createDataPartition(
#     y = summary_df$participant,
#     p = 0.5,
#     list = FALSE,
#     times = 10
#     )

# subsetting the data
# summary_df_train <- summary_df[trainIndex, ]
# summary_df_test  <- summary_df[-trainIndex, ]

# getting unique participants
unique_participants <- unique(summary_df$participant)

# getting the number of participants
num_participants <- length(unique_participants)

# ensuring participants are randomly shuffled
shuffled_participants <- sample(unique_participants)

# defining the number of splits
num_splits <- 10

# creating a dataframe where each participant appears in every split
split_df <- crossing(participant = unique_participants, split_number = 1:10)

# assigning alternating groups (A or B) within each split for each participant
# split_df <- split_df %>% mutate(group = rep(c("A", "B"), length.out = n() ) )
split_df <- split_df %>%
    group_by(split_number) %>%
    # shuffling groups for each split
    mutate(group = sample(rep(c("A", "B"), length.out = n() ) ) ) %>%
    ungroup()

# sanity checks
# table(split_df$group)
# split_df %>%
#     ggplot(aes(x = group) ) +
#     geom_histogram(stat = "count") +
#     facet_wrap(~participant, ncol = 5)

# now for each split, assess the onset and offset
participants_split1_train <- split_df %>%
    filter(split_number == 1 & group == "A") %>%
    pull(participant)
participants_split1_test <- split_df %>%
    filter(split_number == 1 & group == "B") %>%
    pull(participant)

# split1 data
summary_df_split1_train <- summary_df %>%
    filter(participant %in% participants_split1_train)

# fitting the GAM
meta_gam_split1_train <- brm(
    eeg_mean | se(eeg_sd) ~
        condition + s(time, bs = "cr", k = 10, by = condition) +
        (1 | participant),
    data = summary_df_split1_train,
    family = gaussian(),
    warmup = 2000,
    iter = 5000,
    chains = 4,
    cores = 4
    )
```

# Results

...

## Simulation results (bias and variance)

@fig-simulation-mae-variance shows a summary of the simulation results, revealing that the proposed approach (`brms`) has the lowest MAE and variance for both the onset and offset estimates...

```{r fig-simulation-mae-variance, echo = FALSE, fig.width = 9, fig.asp = 0.5, fig.cap = "Median absolute error and variance of onset and offset estimates for each method."}
# loading the simulation results
sim_results <- readRDS(file = "results/sim_results.rds")

# identifying the best brms results
# eps=0 and threshold = 10 or 20 seems pretty good...
# sim_results %>%
#     select(simulation_id:offset_brms) %>%
#     summarise(
#         MAE_onset = median(abs(onset_brms - true_onset) ),
#         variance_onset = var(onset_brms),
#         MAE_offset = median(abs(offset_brms - true_offset) ),
#         variance_offset = var(offset_brms),
#         .by = c(eps, threshold)
#         ) %>%
#     arrange(MAE_onset, MAE_offset) %>%
#     head(10)

# computing and plotting bias, MAE, and variance
# bias := true_onset - median(sim_onset_distrib)
# MAE :=  mean(abs(sim_onset-true_onset))
# variance := variance(sim_onset_distrib)
sim_results %>%
    # keeping only the best brms results
    filter(eps == 0 & threshold == 20) %>%
    select(-eps,-threshold) %>%
    # filtering some alpha_level
    filter(alpha_level == 0.05) %>%
    select(-alpha_level) %>%
    pivot_longer(cols = -simulation_id, names_to = "measure", values_to = "value") %>%
    data.frame() %>%
    mutate(
        error = case_when(
            grepl("onset", measure) ~ abs(value - true_onset),
            grepl("offset", measure) ~ abs(value - true_offset)
            )
        ) %>%
    separate(measure, into = c("type", "method"), sep = "_", extra = "merge") %>%
    group_by(type, method) %>%
    summarise(
        MAE = median(error, na.rm = TRUE),
        variance = var(error, na.rm = TRUE),
        .groups = "drop"
        ) %>%
    ungroup() %>%
    mutate(type = factor(x = type, levels = c("onset", "offset") ) ) %>%
    mutate(
        method = factor(
            x = method,
            levels = c(
                "p", "bh", "by", "holm", "cluster_mass",
                "cluster_tfce", "cpt", "brms"
                ),
            labels = c(
                "Raw p-value", "FDR BH95", "FDR BY01", "Holm", "Cluster-mass",
                "TFCE", "Change point", "brms"
                ),
            )
        ) %>%
    ggplot(
        aes(
            x = MAE,
            y = variance,
            colour = method,
            fill = method
            )
        ) +
    geom_point(
        size = 2,
        pch = 21,
        colour = "white",
        show.legend = FALSE
        ) +
    geom_label_repel(
        aes(label = method),
        colour = "white",
        size = 3,
        segment.color = NA,
        show.legend = FALSE
        ) +
    scale_y_log10() +
    facet_wrap(~type) +
    scale_fill_manual(values = met.brewer(name = "Johnson", n = 8) ) +
    scale_colour_manual(values = met.brewer(name = "Johnson", n = 8) ) +
    labs(x = "Median absolute error (s)", y = "Variance (log-scale)")
```

```{r fig-simulation-distribution, echo = FALSE, fig.width = 9, fig.asp = 0.5, fig.cap = "Distributions of onset and offset estimates for each method."}
sim_results %>%
    # keeping only the best brms results
    filter(eps == 0 & threshold == 20) %>%
    # filtering some alpha_level
    filter(alpha_level == 0.05) %>%
    select(-alpha_level) %>%
    select(-eps,-threshold) %>%
    pivot_longer(
        cols = -simulation_id, 
        names_to = "measure",
        values_to = "value"
        ) %>%
    separate(measure, into = c("type", "method"), sep = "_", extra = "merge") %>%
    data.frame() %>%
    mutate(type = factor(x = type, levels = c("onset", "offset") ) ) %>%
    mutate(
        method = factor(
            x = method,
            levels = c(
                "p", "bh", "by", "holm", "cluster_mass",
                "cluster_tfce", "cpt", "brms"
                ),
            labels = c(
                "Raw p-value", "FDR BH95", "FDR BY01", "Holm",
                "Cluster-mass", "TFCE", "Change point", "brms"
                ),
            )
        ) %>%
    mutate(
        plot_row = ifelse(
            method %in% c("p-value", "FDR BH95", "FDR BY01", "Holm"), 0, 1
            )
        ) %>%
    ggplot(
        aes(
            x = value,
            colour = method,
            fill = method
            )
        ) +
    geom_vline(xintercept = true_onset) +
    geom_vline(xintercept = true_offset) +
    geom_density(aes(fill = NULL) ) +
    facet_grid(plot_row~type, scales = "free_x") +
    theme_light(base_size = 12, base_family = "Open Sans") +
    scale_fill_manual(values = met.brewer(name = "Johnson", n = 8) ) +
    scale_colour_manual(values = met.brewer(name = "Johnson", n = 8) ) +
    labs(x = "Onset/Offset (s)", y = "Density")
```

## Application to actual EEG data (reliability)

...

\newpage

# Discussion

...

## Summary of the proposed approach

...

## Increasing potential usage

Prepare a wrapper `R` package and show how to call it in `Python` and integrate it with `MNE-Python` [@gramfort2013] pipelines...

## Limitations and future directions

Can be applied to any 1D timeseries (e.g., pupillometry, electromyography)... Extending the approach to spatiotemporal data (i.e., time + sensors)...

We kept the exemplary models simple, but can be extended by adding varying/random effects (intercept and slope) for item (e.g., word)... but also continuous predictors at the trial level?

The error properties depend on the threshold parameter, a value of 10 or 20 seems to be a reasonable default, but the optimal threshold parameter can be adjusted using split-half reliability assessment...

## Conclusions

...

\newpage

# Data and code availability

The simulation results as well as the `R` code to reproduce the simulations are available on GitHub: <https://github.com/lnalborczyk/brms_meeg>.

# Packages

```{r, echo = FALSE}
# citing the R packages we have used
cite_packages(
    output = "paragraph",
    omit = c("permuco", "reticulate"),
    out.dir = "."
    )
```

\newpage

# References

::: {#refs}
:::

\newpage

# Appendix

# Application to time-resolved decoding results (accuracy over time)

We conducted time-resolved multivariate pattern analysis (MVPA), also known as decoding. As a result, we have a timecourse of decoding accuracies (e.g., ROC AUC), bounded between 0 and 1, per participant (@fig-mne-decoding)...

```{r fig-sim-decoding, echo = FALSE, eval = TRUE, out.width = "75%", fig.cap = "Exemplary (simulated) group-level average timecourse of binary decoding accuracy (ROC AUC)."}
# simulating decoding accuracies (ROC AUC)
n_participants <- 20
n_timepoints <- 240
timepoints <- seq(from = 0.1, to = 1.3, length.out = n_timepoints) 

# defining a function to generate AUC using a Beta distribution
simulate_auc <- function (
        timepoints, onset = 0.1,
        peak_time = 0.4, sigma = 0.5, amplitude = 30
        ) {
  
    # ensuring timepoints - onset > 0
    adjusted_time <- timepoints - onset + 0.001
    
    # log-normal peak function with right skew
    log_peak <- log(peak_time - onset + 0.001)
    log_t <- log(adjusted_time)
    
    # computing right-skewed alpha with log-normal peak
    alpha_t <- 10 + amplitude * exp(-((log_t - log_peak)^2) / (2 * sigma^2) )
    
    # keeping baseline at chance level (0.5)
    beta_t <- 10
    
    # simulate Beta-distributed AUC values
    auc <- rbeta(length(timepoints), shape1 = alpha_t, shape2 = beta_t)
    
    # returning the AUC
    return (auc)
  
}

# simulating data for all participants
decoding_data <- data.frame(
    participant = rep(1:n_participants, each = n_timepoints),
    time = rep(timepoints, times = n_participants),
    auc = unlist(lapply(1:n_participants, function (i) {
        simulate_auc(
            timepoints,
            onset = 0.1,
            # variable peak time
            peak_time = runif(1, 0.6, 0.7),
            # variable spread
            sigma = runif(1, 0.1, 0.3),
            # variable peak amplitude
            amplitude = runif(1, 30, 40)
            )})
        )
    ) %>%
    mutate(time = time - 0.3)
    
# computing group mean and 95% quantile interval
group_data <- decoding_data %>%
    group_by(time) %>%
    summarise(
        mean_auc = mean(auc),
        lower = quantile(auc, 0.025),
        upper = quantile(auc, 0.975)
        )

# plotting it
# group_data %>%
#     ggplot(aes(x = time, y = mean_auc) ) +
#     geom_hline(yintercept = 0.5, linetype = "dashed") +
#     geom_vline(xintercept = 0.0, linetype = "dashed") +
#     geom_ribbon(aes(ymin = lower, ymax = upper), fill = "steelblue", alpha = 0.2) +
#     geom_line(color = "steelblue", size = 1) +
#     ylim(0, 1) +
#     labs(x = "Time (s)", y = "Decoding accuracy (ROC AUC)")
```

```{r mne-decoding, eval = FALSE, echo = FALSE}
# loading the reticulate package
library(reticulate)

# importing the numpy and mne python modules
np <- import("numpy")
mne <- import("mne")
sklearn <- import("sklearn")

# defining the function in R (it will be executed in Python)
mne_decoding <- function (X, labels, ncores = 8) {
    
    # converting R dataframe to NumPy array (reshaping if needed)
    # X should be a matrix before conversion
    X_np <- np$array(X)
    
    if (length(dim(X_np) ) == 2) {
        
        # adding a second dimension (channels) if missing
        X_np <- np$expand_dims(X_np, axis = as.integer(1) )
        
    }
  
    # defining the classifier
    clf <- sklearn$linear_model$LogisticRegression(solver = "liblinear")
    
    # sliding the estimator on all time frames
    time_decod <- mne$decoding$SlidingEstimator(
        clf, n_jobs = as.integer(ncores),
        scoring = "roc_auc", verbose = TRUE
        )
    
    # or using N-fold cross-validation
    scores <- mne$decoding$cross_val_multiscore(
        time_decod,
        X_np,
        labels,
        cv = as.integer(4),
        n_jobs = as.integer(ncores),
        verbose = TRUE
        )
    
    # returning the scores (averaged over CV folds)
    return (scores)
    
}

# listing all participants
participants <- unique(raw_df$participant)

# initialising empty decoding results
group_decoding_scores <- data.frame()

# running decoding for each participant
for (ppt in participants) {
    
    # printing progress
    print(ppt)
    
    # retrieve data from one participant
    ppt_data <- raw_df %>%
        filter(participant == ppt) %>%
        select(-participant) %>%
        pivot_wider(names_from = time, values_from = eeg) %>%
        select(-condition, -trial)
        
    # extracting the labels
    labels <- raw_df %>%
        filter(participant == ppt) %>%
        select(-participant) %>%
        pivot_wider(names_from = time, values_from = eeg) %>%
        pull(condition) %>%
        as.numeric()
    
    # extracting the timesteps
    timesteps <- raw_df %>%
        filter(participant == ppt) %>%
        select(-participant) %>%
        pull(time) %>%
        unique()
    
    # running the decoding
    decoding_scores <- data.frame(
        mne_decoding(X = ppt_data, labels = labels-1)
        ) %>%
        # computing the average over CV folds
        summarise(across(where(is.numeric), mean) )
    
    # appending to previous results
    group_decoding_scores <- bind_rows(group_decoding_scores, decoding_scores)
    
}

# saving the scores
saveRDS(object = group_decoding_scores, file = "results/decoding_scores.rds")
```

```{r fig-mne-decoding, echo = FALSE, fig.width = 9, fig.cap = "Exemplary average timecourse of binary decoding accuracy (ROC AUC) for each participant. Group-level average decoding accuracy is depicted as a grey background density in each panel."}
# importing the decoding scores
group_decoding_scores <- readRDS(file = "results/decoding_scores.rds")

# extracting the timesteps
timesteps <- raw_df %>%
    pull(time) %>%
    unique()

# plotting it
decoding_summary <- group_decoding_scores %>%
    t() %>%
    data.frame() %>%
    mutate(
        mean = rowMeans(across(1:20) ),
        se = apply(across(1:20), 1, function (x) sd(x) / sqrt(length(x) ) )
        ) %>%
    mutate(lower = mean - se, upper = mean + se) %>%
    mutate(time = timesteps) %>%
    mutate(
        ymin = pmin(mean, 0.5),
        ymax = pmax(mean, 0.5)
        )

# reshaping the decoding data
decoding_data <- group_decoding_scores %>%
    t() %>%
    data.frame() %>%
    mutate(time = timesteps) %>%
    pivot_longer(cols = 1:20) %>%
    mutate(
        participant = rep(
            unique(raw_df$participant),
            n_distinct(raw_df$time)
            )
        ) %>%
    select(participant, time, auc = value)

# plotting it
# group_decoding_scores %>%
#     t() %>%
#     data.frame() %>%
#     mutate(time = timesteps) %>%
#     pivot_longer(cols = 1:20) %>%
#     mutate(
#         participant = rep(
#             unique(raw_df$participant),
#             n_distinct(raw_df$time)
#             )
#         ) %>%
decoding_data %>%
    ggplot(aes(x = time) ) +
    geom_hline(yintercept = 0.5, linetype = "dashed") +
    geom_vline(xintercept = true_onset, linetype = "dashed") +
    geom_line(aes(y = auc), linewidth = 0.5) +
    facet_wrap(~participant) +
    geom_ribbon(
        data = decoding_summary,
        aes(x = time, ymin = ymin, ymax = ymax),
        alpha = 0.5
        ) +
    labs(x = "Time (s)", y = "Decoding accuracy (ROC AUC)")
```

Now, we want to *test* whether the group-level average decoding accuracy is above chance (i.e., 0.5) at each timestep. We use a similar GAM/GP as previously, but we replace the $\mathrm{Normal}$ likelihood function by a $\mathrm{Beta}$ one to account for the bounded nature of AUC values (between 0 and 1).

```{r gam-decoding, message = FALSE}
# fitting the GAM
decoding_gam <- brm(
    auc ~ s(time, bs = "cr", k = 10),
    data = decoding_data,
    family = Beta(),
    iter = 5000,
    chains = 4,
    cores = 4,
    file = "models/decoding_gam.rds"
    )
```

```{r gp-decoding, message = FALSE}
# fitting the GP
decoding_gp <- brm(
    auc ~ gp(time, k = 20),
    data = decoding_data,
    family = Beta(),
    control = list(adapt_delta = 0.99),
    iter = 5000,
    chains = 4,
    cores = 4,
    file = "models/decoding_gp.rds"
    )
```

```{r decoding-preds, echo = FALSE, fig.width = 9, fig.asp = 0.5, fig.cap = "Posterior predictions of the GAM (left) and GP (right) fitted on decoding accuracy over time."}
# plotting the posterior predictions
gam_decoding_preds <- plot(
    conditional_effects(x = decoding_gam, prob = 0.99),
    points = TRUE,
    point_args = list(size = 1, pch = 21, colour = "grey"),
    line_args = list(colour = "black"),
    theme = theme_light(), plot = FALSE
    )[[1]] +
    geom_hline(yintercept = 0.5, linetype = 2) +
    geom_vline(xintercept = true_onset, linetype = 2) +
    ylim(0, 1) +
    labs(x = "Time (s)", y = "Decoding accuracy (ROC AUC)")

gp_decoding_preds <- plot(
    conditional_effects(x = decoding_gp, prob = 0.99),
    points = TRUE,
    point_args = list(size = 1, pch = 21, colour = "grey"),
    line_args = list(colour = "black"),
    theme = theme_light(), plot = FALSE
    )[[1]] +
    geom_hline(yintercept = 0.5, linetype = 2) +
    geom_vline(xintercept = true_onset, linetype = 2) +
    ylim(0, 1) +
    labs(x = "Time (s)", y = "Decoding accuracy (ROC AUC)")

# combining the two plots
gam_decoding_preds + gp_decoding_preds
```

Next, we plot the posterior probability of decoding accuracy being above chance level (plus some epsilon) (@fig-decoding-post).

```{r fig-decoding-post, echo = FALSE, fig.width = 9, fig.asp = 0.5, fig.cap = "Posterior probability of decoding accuracy being above chance level according to the GAM (left) or the GP (right)."}
# defining a function to plot posterior prob of slope above 0
plot_post_decoding <- function (model, data, chance_level = 0.5, eps = 0.1) {
    
    # defining a sequence of time values to make predictions
    time_seq <- crossing(time = seq(min(data$time), max(data$time), length.out = 100) )
  
    # retrieving posterior samples
    posterior_samples <- posterior_epred(object = model, newdata = time_seq)
    
    # computing the probability that y is above 0
    prob_y_above_0 <- data.frame(
        time = time_seq$time,
        m = colMeans(posterior_samples > (chance_level + eps) ),
        lower = apply(
            X = posterior_samples > (chance_level + eps),
            MARGIN = 2, FUN = quantile, probs = 0.025
            ),
        upper = apply(
            X = posterior_samples > (chance_level + eps),
            MARGIN = 2, FUN = quantile, probs = 0.975
            )
        )
    
    # plotting it
    prob_y_above_0 %>%
    ggplot(aes(x = time, y = m) ) +
    geom_hline(yintercept = chance_level, linetype = 2) +
    geom_vline(xintercept = true_onset, linetype = 2) +
    geom_line() +
    labs(x = "Time (s)", y = expression(Pr(AUC>chance~"|"~data, model) ) )
  
}

# using the function with the two models
plot_post_decoding(
    model = decoding_gam, data = decoding_data,
    chance_level = 0.5, eps = 0.1
    ) +
    plot_post_decoding(
        model = decoding_gp, data = decoding_data,
        chance_level = 0.5, eps = 0.1
        ) 
```

```{r fig-decoding-ratio, echo = FALSE, fig.width = 9, fig.asp = 0.5, fig.cap = "Ratio of posterior probabilities of decoding accuracy being above chance level according to the GAM (left) or the GP (right)."}
# defining a function to plot posterior prob of slope above 0
plot_post_decoding_ratio <- function (model, data, chance_level = 0.5, eps = 0.1) {
    
    # defining a sequence of time values to make predictions
    time_seq <- data.frame(time = data$time)
    
    # retrieving posterior samples
    posterior_samples <- posterior_epred(object = model, newdata = time_seq)
    
    # computing the probability that y is above 0
    prob_y_above_0 <- data.frame(time = data$time) %>%
        mutate(m = colMeans(posterior_samples > (chance_level + eps) ) ) %>%
        mutate(prob_ratio = m / (1 - m) )
    
    # printing the identified clusters
    threshold <- 10
    exceeding_times <- prob_y_above_0 %>%
        dplyr::filter(prob_ratio > threshold) %>%
        summarise(cluster_onset = min(time), cluster_offset = max(time) )
    
    # printing the identified clusters
    # print(exceeding_times)
    
    # plotting it
    prob_y_above_0 %>%
        mutate(above_thres = ifelse(prob_ratio > threshold, 1, NA) ) %>%
        ggplot(aes(x = time, y = prob_ratio) ) +
        geom_hline(yintercept = 1, linetype = "dashed") +
        geom_hline(yintercept = 3, linetype = "dashed", color = "darkred") +
        geom_hline(yintercept = 1/3, linetype = "dashed", color = "darkred") +
        geom_hline(yintercept = 10, linetype = "dashed", color = "red") +
        geom_hline(yintercept = 1/10, linetype = "dashed", color = "red") +
        geom_hline(yintercept = 100, linetype = "dashed", color = "orangered") +
        geom_hline(yintercept = 1/100, linetype = "dashed", color = "orangered") +
        geom_vline(xintercept = true_onset, linetype = 2) +
        geom_line() +
        geom_point(
            data = . %>% dplyr::filter(!is.na(above_thres) ),
            aes(y = threshold),
            colour = "darkgreen",
            shape = 15,
            size = 3,
            na.rm = TRUE
            ) +
        scale_y_log10(labels = label_log(digits = 2), limits = c(NA, 1e4) ) +
        labs(
            x = "Time (s)",
            y = expression(
                Pr(AUC>chance~"|"~data) / (1 - Pr(AUC>chance~"|"~data) )
                )
            )
  
}

# using the function with the two models
plot_post_decoding_ratio(
    model = decoding_gam, data = decoding_data,
    chance_level = 0.5, eps = 0.05
    ) +
    plot_post_decoding_ratio(
        model = decoding_gp, data = decoding_data,
        chance_level = 0.5, eps = 0.05
        )
```

\newpage

# Application to 2D time-resolved decoding results (cross-temporal generalisation)

Assume we have M/EEG data and we have conducted cross-temporal generalisation analyses [@king2014]. As a result, we have a 2D matrix where each element contains the decoding accuracy (e.g., ROC AUC) of a classifier trained at timestep $\text{training}_{i}$ and tested at timestep $\text{testing}_{j}$ (@fig-sim-timegen).

```{r fig-sim-timegen, echo = FALSE, dpi = 300, fig.cap = "Exemplary (simulated) group-level average cross-temporal generalisation matrix of decoding performance (ROC AUC)."}
# number of participants
n_participants <- 10

# number of timepoints
# n_timepoints <- 240 # (1.2s at 200Hz)
n_timepoints <- 60 # (1.2s at 50Hz)
timepoints <- seq(from = -0.2, to = 1, length.out = n_timepoints)

# smooth onset and offset parameters
decode_onset <- 0.2
decode_offset <- 0.3

# smoothness of onset/offset
sigma_smooth <- 0.05

# generating participant-specific cross-temporal generalisation matrices
timegen_data <- tibble()

# for each participant
for (p in 1:n_participants) {
  
    # adding variability in peak amplitude and width per participant
    peak_variability <- runif(1, 30, 50) # random peak strength (higher = stronger decoding)
    smooth_variability <- runif(1, 0.04, 0.06) # random smoothness variation
    onset_variability <- runif(1, -0.05, 0.05) # small jitter in onset time
    offset_variability <- runif(1, -0.05, 0.05) # small jitter in offset time
    
    # computing smooth transition function (soft onset and offset with participant variation)
    decode_window <- outer(timepoints, timepoints, function (t1, t2) {
        
        # smooth onset
        onset_factor <- 1 /
            (1 + exp(-(t1 - (decode_onset + onset_variability) ) / sigma_smooth) )
        
        # smooth offset
        offset_factor <- 1 /
            (1 + exp((t1 - (decode_offset + offset_variability)) / sigma_smooth) )
        
        # diagonal Gaussian
        onset_factor * offset_factor * exp(-((t1 - t2)^2) / (2 * smooth_variability^2) )
        
    })
    
    # defining smooth alpha and beta parameters for Beta distribution
    base_alpha <- 10
    peak_alpha <- peak_variability
    alpha_matrix <- base_alpha + peak_alpha * decode_window
    beta_matrix <- base_alpha
    
    # generating AUC values using the Beta distribution
    auc_matrix_beta <- matrix(
        rbeta(n_timepoints^2, shape1 = alpha_matrix, shape2 = beta_matrix),
        nrow = n_timepoints, ncol = n_timepoints
        )
    
    # converting to long format for plotting
    temp_data <- expand.grid(
        train_time = timepoints, test_time = timepoints
        ) %>%
        mutate(auc = as.vector(auc_matrix_beta), participant = p)
    
    # storing results
    timegen_data <- bind_rows(timegen_data, temp_data)
    
}

# plotting cross-temporal generalization matrix
timegen_data %>%
    summarise(auc = mean(auc), .by = c(train_time, test_time) ) %>%
    ggplot(aes(x = train_time, y = test_time, fill = auc) ) +
    geom_tile() +
    geom_vline(xintercept = 0, linetype = 2, linewidth = 0.5) +
    geom_hline(yintercept = 0, linetype = 2, linewidth = 0.5) +
    geom_abline(slope = 1, intercept = 0, linetype = 2, linewidth = 0.5) +
    scale_x_continuous(expand = c(0, 0) ) +
    scale_y_continuous(expand = c(0, 0) ) + 
    coord_fixed() +
    scale_fill_scico(palette = "vik", midpoint = 0.5, name = "AUC") +
    labs(x = "Testing time (s)", y = "Training time (s)")
```

```{r mne-timegen, eval = FALSE, echo = FALSE}
# defining the function in R (it will be executed in Python)
mne_timegen <- function (X, labels, ncores = 8) {
    
    # converting R dataframe to NumPy array (reshaping if needed)
    # X should be a matrix before conversion
    X_np <- np$array(X)
    
    if (length(dim(X_np) ) == 2) {

        # adding a second dimension (channels) if missing
        X_np <- np$expand_dims(X_np, axis = as.integer(1) )

    }
  
    # defining the classifier
    clf <- sklearn$linear_model$LogisticRegression(solver = "liblinear")
    
    # sliding the estimator on all time frames
    time_gen <- mne$decoding$GeneralizingEstimator(
        clf,
        n_jobs = as.integer(ncores),
        scoring = "roc_auc",
        verbose = FALSE
        )
    
    # or using N-fold cross-validation
    scores <- mne$decoding$cross_val_multiscore(
        time_gen,
        X_np,
        labels,
        cv = as.integer(4),
        n_jobs = as.integer(ncores),
        verbose = FALSE
        )
    
    # returning the scores
    return (scores)
    
}

# listing all participants
participants <- unique(raw_df$participant)

# initialising empty decoding results
group_timegen_scores <- data.frame()

# running decoding for each participant
for (ppt in participants) {
    
    # printing progress
    print(ppt)
    
    # retrieve data from one participant
    ppt_data <- raw_df %>%
        filter(participant == ppt) %>%
        select(-participant) %>%
        pivot_wider(names_from = time, values_from = eeg) %>%
        select(-condition, -trial)
        
    # extracting the labels
    labels <- raw_df %>%
        filter(participant == ppt) %>%
        select(-participant) %>%
        pivot_wider(names_from = time, values_from = eeg) %>%
        pull(condition) %>%
        as.numeric()
    
    # extracting the timesteps
    timesteps <- raw_df %>%
        filter(participant == ppt) %>%
        select(-participant) %>%
        pull(time) %>%
        unique()
    
    # running the decoding
    timegen_scores <- mne_timegen(
        X = ppt_data,
        labels = labels-1
        )
    
    # computing the average over CV folds
    # a <- timegen_scores %>%
    #     apply(MARGIN = c(2, 3), FUN = mean) %>%
    #     data.frame()
    timegen_scores <- data.frame(np$mean(timegen_scores, axis = as.integer(0) ) )
    
    # sanity check
    # image(as.matrix(timegen_scores) )
    
    # appending to previous results
    group_timegen_scores <- bind_rows(group_timegen_scores, timegen_scores)
    
}

# saving the scores
saveRDS(object = group_timegen_scores, file = "results/timegen_scores.rds")

# reshaping the data
colnames(group_timegen_scores) <- unique(raw_df$time)
timegen_data <- group_timegen_scores %>%
    mutate(participant = rep(x = participants, each = n_distinct(raw_df$time) ) ) %>%
    mutate(train_time = rep(x = unique(raw_df$time), times = length(participants) ) ) %>%
    pivot_longer(
        cols = -c(participant, train_time),
        names_to = "test_time",
        values_to = "auc"
        ) %>%
    mutate(test_time = as.numeric(test_time) )
```

Now, we want to test whether and when decoding performance is above chance level (0.5 for a binary decoding task). These two models are computationally heavier to fit (more observations and 2D smooth functions)...

```{r gam-gp-timegen, message = FALSE}
# fitting a GAM with two temporal dimensions
timegen_gam <- brm(
    # 2D thin-plate spline (tp)
    # auc ~ s(train_time, test_time, bs = "tp", k = 10),
    auc ~ t2(train_time, test_time, bs = "tp", k = 10),
    data = timegen_data,
    family = Beta(),
    iter = 5000,
    chains = 4,
    cores = 4,
    file = "models/timegen_gam_t2.rds"
    )

# fitting a GP with two temporal dimensions
# timegen_gp <- brm(
#     auc ~ gp(train_time, test_time, k = 20),
#     data = timegen_data,
#     family = Beta(),
#     control = list(adapt_delta = 0.95),
#     iter = 2000,
#     chains = 4,
#     cores = 4,
#     file = "models/timegen_gp.rds"
#     )
```

```{r gam-timegen-preds, eval = FALSE, echo = FALSE, fig.cap = "Posterior predictions of the GAM fitted on decoding accuracy over time."}
# plotting the posterior predictions
plot(
    conditional_effects(x = timegen_gam, prob = 0.95),
    points = FALSE,
    # point_args = list(size = 1, pch = 21, colour = "grey"),
    # line_args = list(colour = "black"),
    method = "posterior_epred",
    surface = TRUE,
    theme = theme_light(),
    plot = TRUE
    )#[[1]] +
    # geom_hline(yintercept = 0.5, linetype = 2) +
    # geom_vline(xintercept = 0.0, linetype = 2) +
    # ylim(0, 1) +
    # labs(x = "Time (s)", y = "Decoding accuracy (ROC AUC)")

# posterior predictive checks
pp_check(timegen_gam)
```

```{r gam-timegen-post-preds, echo = FALSE, fig.width = 8, fig.asp = 0.6, fig.cap = "Posterior probability of decoding accuracy being above chance level (2D GAM)."}
# defining a function to plot posterior prob of slope above 0
plot_post_timegen <- function (model, data, chance_level = 0.5, eps = 0.1) {
    
    # defining a sequence of x values to make predictions
    preds_conds <- crossing(
        train_time = unique(data$train_time)[c(TRUE, FALSE)],
        test_time = unique(data$test_time)[c(TRUE, FALSE)]
        )
    
    # retrieving posterior predictions
    post_preds <- conditional_effects(
        x = model,
        conditions = preds_conds,
        method = "posterior_epred",
        prob = 0.95,
        ndraws = 100
        )[[1]]
    
    # plotting cross-temporal generalization matrix
    post_preds_plot <- post_preds %>%
        summarise(auc = mean(estimate__), .by = c(train_time, test_time) ) %>%
        ggplot(aes(x = train_time, y = test_time, fill = auc) ) +
        geom_tile() +
        geom_vline(xintercept = 0, linetype = 2, linewidth = 0.5) +
        geom_hline(yintercept = 0, linetype = 2, linewidth = 0.5) +
        geom_abline(slope = 1, intercept = 0, linetype = 2, linewidth = 0.5) +
        scale_x_continuous(expand = c(0, 0) ) +
        scale_y_continuous(expand = c(0, 0) ) + 
        coord_fixed() +
        scale_fill_scico(palette = "vik", midpoint = 0.5, name = "AUC") +
        labs(x = "Testing time (s)", y = "Training time (s)")

    # retrieving posterior samples
    posterior_samples <- posterior_epred(object = model, newdata = preds_conds)
    
    # computing the probability that y is above 0
    prob_y_above_0 <- preds_conds %>%
        mutate(post_prob = colMeans(posterior_samples) ) %>%
        mutate(m = colMeans(posterior_samples > (chance_level + eps) ) ) %>%
        mutate(prob_ratio = m / (1 - m) )
        
    # plotting it
    # prob_y_above_0 %>% filter(prob_ratio != Inf) %>% pull(prob_ratio) %>% range()
    prob_above_chance_plot <- prob_y_above_0 %>%
        mutate(prob_ratio = ifelse(prob_ratio == Inf, 2000, prob_ratio) ) %>%
        mutate(prob_ratio = ifelse(prob_ratio == 0, 0.0005, prob_ratio) ) %>%
        ggplot(aes(x = train_time, y = test_time, fill = prob_ratio) ) +
        geom_tile() +
        geom_vline(xintercept = 0, linetype = 2, linewidth = 0.5) +
        geom_hline(yintercept = 0, linetype = 2, linewidth = 0.5) +
        geom_abline(slope = 1, intercept = 0, linetype = 2, linewidth = 0.5) +
        scale_x_continuous(expand = c(0, 0) ) +
        scale_y_continuous(expand = c(0, 0) ) + 
        coord_fixed() +
        scale_fill_scico(palette = "vik", midpoint = 0, name = "p/(1-p)", trans = "log10") +
        # scale_fill_scico(palette = "vik", midpoint = 1, name = "p/(1-p)") +
        # theme_light() +
        labs(x = "Testing time (s)", y = "Training time (s)")
    
    # combining the two plots
    post_preds_plot + prob_above_chance_plot
    
    # some tests
    # post_preds_plot +
    #     geom_contour(
    #         data = prob_y_above_0,
    #         aes(x = train_time, y = test_time, z = prob_ratio),
    #         breaks = 10,
    #         color = "red",
    #         linewidth = 1,
    #         inherit.aes = FALSE
    #         )
  
}

# using the function with the decoding GAM
plot_post_timegen(model = timegen_gam, data = timegen_data, chance_level = 0.5, eps = 0.01)
```

```{r gp-timegen-preds, eval = FALSE, echo = FALSE, fig.cap = "Posterior predictions of the GP fitted on decoding accuracy over time."}
# plotting the posterior predictions
plot(
    conditional_effects(x = timegen_gp, prob = 0.95),
    points = FALSE,
    method = "posterior_epred",
    surface = TRUE,
    theme = theme_light(),
    plot = TRUE
    )

# posterior predictive checks
pp_check(timegen_gp)

# checking timecourse of timegen_data's diagonal
timegen_data %>%
    filter(train_time == test_time) %>%
    summarise(auc = mean(auc), .by = train_time) %>%
    ggplot(aes(x = train_time, y = auc) ) +
    geom_hline(yintercept = 0.5, linetype = 2) +
    geom_line() +
    labs(x = "Time (s)", y = "AUC")
```

\newpage

# Mathematical formulation of the bivariate GAM

```{=html}
<!--

See https://bookdown.org/epeterson_2010/bios526_book/Module_5_3.html#bivariate-splines

-->
```

To model cross-temporal generalisation matrices of decoding performance (ROC AUC), we extended the initial (decoding) GAM to take into account the bivariate temporal distribution of AUC values, thus producing naturally smoothed estimates (timecourses) of AUC values and posterior probabilities. This model can be written as follows:

$$
\begin{aligned}
\text{AUC}_{i} &\sim \mathrm{Beta}(\mu_{i}, \phi)\\
g(\mu_{i}) &= f \left(\text{train}_{i}, \text{test}_{i} \right)\\
\end{aligned}
$$

where we assume that AUC values come from a $\mathrm{Beta}$ distribution with two parameters $\mu$ and $\phi$. We can think of $f \left(\text{train}_{i}, \text{test}_{i} \right)$ as a surface (a smooth function of two variables) that we can model using a 2-dimensional splines. Let $\mathbf{s}_{i} = \left(\text{train}_{i}, \text{test}_{i} \right)$ be some pair of training and testing samples, and let $\mathbf{k}_{m} = \left(\text{train}_{m}, \text{test}_{m} \right)$ denote the $m^{\text{th}}$ knot in the domain of $\text{train}_{i}$ and $\text{test}_{i}$. We can then express the smooth function as:

$$
f \left(\text{train}_{i}, \text{test}_{i} \right) = \alpha + \sum_{m=1}^M \beta_{m} b_{m} \left(\tilde{s}_{i}, \tilde{k}_{m} \right)
$$

Note that $b_{m}(,)$ is a basis function that maps $R \times R \rightarrow R$. A popular bivariate basis function uses *thin-plate splines* [@wood2003], which extend to $\mathbf{s}_{i} \in \mathbb{R}^{d}$ and $\partial l_{g}$ penalties. These splines are designed to interpolate and approximate smooth surfaces over two dimensions (hence the "bivariate" term). For $d=2$ dimensions and $l=2$ (smoothness penalty involving second order derivative):

$$
f \left(\tilde{s}_{i} \right) = \alpha + \beta_{1} x_{i} + \beta_{2} z_{i} +\sum_{m=1}^{M} \beta_{2+m} b_m\left(\tilde{s}_i, \tilde{k}_m\right)
$$

using the the radial basis function given by:

$$
b_m\left(\tilde{s}_i, \tilde{k}_m\right)=\left\|\tilde{s}_i-\tilde{k}_m\right\|^2 \log \left\|\tilde{s}_i-\tilde{k}_m\right\|
$$

where $\left\|\mathbf{s}_i-\mathbf{k}_{m}\right\|$ is the Euclidean distance between the covariate $\mathbf{s}_{i}$ and the knot location $\mathbf{k}_{m}$.

\newpage

# Threshold-free cluster enhancement

Cluster-based permutation approaches require defining a cluster-forming threshold (e.g., a t- or f-value) as the initial step of the algorithm. As different cluster-forming thresholds lead to clusters with different spatial or temporal extent, this threshold modulates the sensitivity of the subsequent permutation test. The threshold-free cluster enhancement method (TFCE) was introduced by @smith2009 to overcome this arbitrary threshold.

In brief, the TFCE method works as follows. Instead of picking an arbitrary cluster-forming threshold (e.g., $t=2$), we try all (or many) possible thresholds in a given range and check whether a given timestep/voxel belongs to a significant cluster under any of the set of thresholds... Then, instead of using cluster mass, we use a weighted average between the cluster extend ($e$, how broad is the cluster, that is, how many connected samples it contains) and the cluster height ($h$, how high is the cluster, that is, how large is the test statistic) according to the formula:

$$
\text{TFCE} = \int_{h} e(h)^{E} h^{H} \mathrm{d}h
$$

Where... the parameters $E$ and $H$ are set a priori and control the influence of the extend and height on the TFCE. Then, p-value for timestep/voxel $i$ is computed by comparing it TFCE with the null distribution of TFCE values. For each permuted signal, we keep the maximal value over the whole signal for the null distribution of the TFCE.... But see @sassenhagen2019...

\newpage

# Integration with `MNE-Python`

Explain how to use the `R` package with `MNE` epochs...

```{r r-python, eval = FALSE}
# suggest a package name
library(available)
suggest(
    text = "Time-resolved electrophysiological measurements such as those offered by magneto- or electro-encephalography (M/EEG) provide a unique window onto neural activity underlying cognitive processes. Typically, researchers are interested in testing whether and when such measures differ across conditions and/or groups. The conventional approach consists in conducting mass-univariate statistics through time followed by some form of multiplicity correction (e.g., FDR, FWER) or cluster-based inference. However, these cluster-based methods have an important downside: they shift the focus of inference from the timepoint to the cluster level, thus preventing any conclusion to be made about the onset or offset of effects (e.g., differences across conditions or groups). Here, we introduce a *model-based* approch for analysing M/EEG timeseries such as ERPs or timecourses of decoding performance and their differences across conditions or groups. This approach relies on Bayesian generalised additive multilevel models, which output the posterior probabilility of the effect being above 0 (or above chance) at every timestep, while naturally taking into account the temporal dependencies and between-subject variability present in such data. Using both simulation and actual EEG data, we show that the proposed approach largely outperforms conventional methods in determining both the onset and offset of M/EEG effects (e.g., ERPs difference, decoding performance), producting more precise and more reliable estimates. We provide an R package implementing the approach and illustrate how to integrate it into M/EEG statistical pipelines in MNE-Python."
    )

available:::namr(
    title = "Precise temporal localisation of M/EEG effects with Bayesian generalised additive multilevel models",
    verb = TRUE
    )

# to-do adding some code here...
```
